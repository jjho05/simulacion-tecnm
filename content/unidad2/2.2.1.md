# 2.2.1 De Uniformidad

Las pruebas de uniformidad son fundamentales para verificar que un generador de números pseudoaleatorios produce valores que se distribuyen equitativamente en el intervalo [0,1]. Sin uniformidad, los resultados de la simulación serán sesgados e inválidos.

---

## Importancia de la Uniformidad

### ¿Por qué es crítica?

**Uniformidad significa:**
- Cada subintervalo de [0,1] tiene la misma probabilidad
- No hay valores "favoritos" o "evitados"
- La distribución empírica coincide con la teórica

**Sin uniformidad:**
- ❌ Resultados de simulación sesgados
- ❌ Intervalos de confianza incorrectos
- ❌ Decisiones erróneas basadas en datos incorrectos

### Ejemplo Visual

```
Generador BUENO (uniforme):
[0.0-0.2]: ████████████ (20%)
[0.2-0.4]: ████████████ (20%)
[0.4-0.6]: ████████████ (20%)
[0.6-0.8]: ████████████ (20%)
[0.8-1.0]: ████████████ (20%)

Generador MALO (no uniforme):
[0.0-0.2]: ████ (8%)
[0.2-0.4]: ████████████████████ (40%)
[0.4-0.6]: ████████ (16%)
[0.6-0.8]: ████████████ (24%)
[0.8-1.0]: ██████ (12%)
```

---

## Prueba Chi-Cuadrada (χ²)

### Descripción

La prueba más común y ampliamente utilizada para verificar uniformidad. Compara frecuencias observadas vs. esperadas.

### Hipótesis

- **H₀ (nula):** Los números son uniformes en [0,1]
- **H₁ (alternativa):** Los números NO son uniformes

### Procedimiento Paso a Paso

**1. Dividir el intervalo [0,1] en k subintervalos**

Típicamente k = 10 o k = √n

**2. Contar frecuencias observadas (Oᵢ)**

Número de valores que caen en cada intervalo

**3. Calcular frecuencias esperadas (Eᵢ)**

$$E_i = \frac{n}{k}$$

donde n = total de números generados

**4. Calcular estadístico Chi-cuadrada**

$$\chi^2_0 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i}$$

**5. Obtener valor crítico**

De tabla: $\chi^2_{\alpha, k-1}$

Típicamente α = 0.05 (95% confianza)

**6. Decisión**

- Si $\chi^2_0 < \chi^2_{\alpha, k-1}$ → **Aceptar H₀** (uniforme)
- Si $\chi^2_0 \geq \chi^2_{\alpha, k-1}$ → **Rechazar H₀** (no uniforme)

### Ejemplo Numérico Completo

**Datos:**
- n = 50 números generados
- k = 5 intervalos
- α = 0.05

**Números generados:**
```
0.12, 0.45, 0.89, 0.23, 0.67, 0.34, 0.78, 0.01, 0.56, 0.90,
0.15, 0.48, 0.82, 0.27, 0.61, 0.38, 0.72, 0.05, 0.51, 0.94,
0.18, 0.42, 0.85, 0.21, 0.64, 0.31, 0.75, 0.08, 0.53, 0.97,
0.11, 0.46, 0.88, 0.24, 0.68, 0.35, 0.79, 0.02, 0.57, 0.91,
0.16, 0.49, 0.83, 0.28, 0.62, 0.39, 0.73, 0.06, 0.54, 0.95
```

**Paso 1: Definir intervalos**

| Intervalo | Rango |
|-----------|-------|
| 1 | [0.0, 0.2) |
| 2 | [0.2, 0.4) |
| 3 | [0.4, 0.6) |
| 4 | [0.6, 0.8) |
| 5 | [0.8, 1.0) |

**Paso 2: Contar frecuencias observadas**

| Intervalo | Oᵢ |
|-----------|----|
| 1 | 12 |
| 2 | 8 |
| 3 | 11 |
| 4 | 9 |
| 5 | 10 |

**Paso 3: Frecuencia esperada**

$$E_i = \frac{50}{5} = 10$$

**Paso 4: Calcular χ²**

$$\chi^2_0 = \frac{(12-10)^2}{10} + \frac{(8-10)^2}{10} + \frac{(11-10)^2}{10} + \frac{(9-10)^2}{10} + \frac{(10-10)^2}{10}$$

$$= \frac{4}{10} + \frac{4}{10} + \frac{1}{10} + \frac{1}{10} + \frac{0}{10}$$

$$= 0.4 + 0.4 + 0.1 + 0.1 + 0 = 1.0$$

**Paso 5: Valor crítico**

De tabla: $\chi^2_{0.05, 4} = 9.488$

**Paso 6: Decisión**

$\chi^2_0 = 1.0 < 9.488$

✅ **Conclusión:** Se acepta H₀. Los números son uniformes.

### Implementación en Python

```python
import numpy as np
from scipy import stats

def prueba_chi_cuadrada(numeros, k=10, alpha=0.05):
    """
    Prueba Chi-cuadrada para uniformidad.
    
    Args:
        numeros: Array de números en [0,1]
        k: Número de intervalos
        alpha: Nivel de significancia
    
    Returns:
        dict con resultados de la prueba
    """
    n = len(numeros)
    
    # Frecuencias observadas
    observadas, _ = np.histogram(numeros, bins=k, range=(0,1))
    
    # Frecuencias esperadas
    esperadas = np.full(k, n/k)
    
    # Estadístico Chi-cuadrada
    chi2_calc = np.sum((observadas - esperadas)**2 / esperadas)
    
    # Valor crítico
    grados_libertad = k - 1
    chi2_critico = stats.chi2.ppf(1 - alpha, grados_libertad)
    
    # P-value
    p_value = 1 - stats.chi2.cdf(chi2_calc, grados_libertad)
    
    # Decisión
    acepta_h0 = chi2_calc < chi2_critico
    
    return {
        'chi2_calculado': chi2_calc,
        'chi2_critico': chi2_critico,
        'p_value': p_value,
        'acepta_uniformidad': acepta_h0,
        'observadas': observadas,
        'esperadas': esperadas
    }

# Ejemplo de uso
np.random.seed(42)
numeros = np.random.random(100)

resultado = prueba_chi_cuadrada(numeros, k=10, alpha=0.05)

print(f"χ² calculado: {resultado['chi2_calculado']:.4f}")
print(f"χ² crítico: {resultado['chi2_critico']:.4f}")
print(f"P-value: {resultado['p_value']:.4f}")
print(f"¿Acepta uniformidad? {'SÍ' if resultado['acepta_uniformidad'] else 'NO'}")

# Mostrar tabla de frecuencias
print("\nTabla de frecuencias:")
print("Intervalo | Observada | Esperada | (O-E)²/E")
print("-" * 50)
for i in range(10):
    o = resultado['observadas'][i]
    e = resultado['esperadas'][i]
    contrib = (o - e)**2 / e
    print(f"   {i+1:2d}     |    {o:2.0f}     |   {e:4.1f}   |  {contrib:.4f}")
```

### Interpretación del P-value

**P-value:** Probabilidad de observar un χ² tan extremo si H₀ es verdadera

| P-value | Interpretación |
|---------|----------------|
| > 0.10 | Fuerte evidencia de uniformidad |
| 0.05 - 0.10 | Evidencia moderada |
| 0.01 - 0.05 | Evidencia débil |
| < 0.01 | Rechazar uniformidad |

---

## Prueba de Kolmogorov-Smirnov (K-S)

### Descripción

Prueba no paramétrica que compara la función de distribución acumulada (CDF) empírica con la teórica.

**Ventajas sobre Chi-cuadrada:**
- No requiere agrupar datos en intervalos
- Más potente para muestras pequeñas
- Detecta diferencias en cualquier parte de la distribución

### Estadístico K-S

$$D = \max_{1 \leq i \leq n} |F(x_i) - S_n(x_i)|$$

Donde:
- $F(x)$ = CDF teórica (uniforme: F(x) = x)
- $S_n(x)$ = CDF empírica

### Procedimiento

**1. Ordenar los números**

$x_1 \leq x_2 \leq ... \leq x_n$

**2. Calcular CDF empírica**

$$S_n(x_i) = \frac{i}{n}$$

**3. Calcular CDF teórica**

Para uniforme [0,1]: $F(x_i) = x_i$

**4. Calcular D**

$$D = \max\left(\max_i\left|\frac{i}{n} - x_i\right|, \max_i\left|x_i - \frac{i-1}{n}\right|\right)$$

**5. Comparar con valor crítico**

De tabla K-S o aproximación: $D_{\alpha} = \frac{c_{\alpha}}{\sqrt{n}}$

Para α=0.05: $c_{0.05} \approx 1.36$

### Ejemplo Numérico

**Datos:** 10 números ordenados

```
x: 0.05, 0.12, 0.23, 0.34, 0.45, 0.56, 0.67, 0.78, 0.89, 0.95
```

**Cálculos:**

| i | xᵢ | F(xᵢ)=xᵢ | Sₙ(xᵢ)=i/10 | \|F-Sₙ\| | \|F-Sₙ₋₁\| |
|---|-----|----------|-------------|----------|------------|
| 1 | 0.05 | 0.05 | 0.10 | 0.05 | 0.05 |
| 2 | 0.12 | 0.12 | 0.20 | 0.08 | 0.02 |
| 3 | 0.23 | 0.23 | 0.30 | 0.07 | 0.03 |
| 4 | 0.34 | 0.34 | 0.40 | 0.06 | 0.04 |
| 5 | 0.45 | 0.45 | 0.50 | 0.05 | 0.05 |
| 6 | 0.56 | 0.56 | 0.60 | 0.04 | 0.06 |
| 7 | 0.67 | 0.67 | 0.70 | 0.03 | 0.07 |
| 8 | 0.78 | 0.78 | 0.80 | 0.02 | 0.08 |
| 9 | 0.89 | 0.89 | 0.90 | 0.01 | 0.09 |
| 10 | 0.95 | 0.95 | 1.00 | 0.05 | 0.05 |

**D = max(0.09) = 0.09**

**Valor crítico:**

$$D_{0.05} = \frac{1.36}{\sqrt{10}} = 0.430$$

**Decisión:**

$D = 0.09 < 0.430$

✅ **Conclusión:** Acepta uniformidad

### Implementación en Python

```python
from scipy import stats

def prueba_kolmogorov_smirnov(numeros, alpha=0.05):
    """
    Prueba K-S para uniformidad.
    
    Args:
        numeros: Array de números en [0,1]
        alpha: Nivel de significancia
    
    Returns:
        dict con resultados
    """
    n = len(numeros)
    
    # Prueba K-S (scipy lo hace automáticamente)
    d_stat, p_value = stats.kstest(numeros, 'uniform')
    
    # Valor crítico aproximado
    d_critico = 1.36 / np.sqrt(n)  # Para alpha=0.05
    
    # Decisión
    acepta_h0 = d_stat < d_critico
    
    # Cálculo manual para visualización
    numeros_ord = np.sort(numeros)
    cdf_empirica = np.arange(1, n+1) / n
    cdf_teorica = numeros_ord
    
    diferencias = np.abs(cdf_empirica - cdf_teorica)
    d_manual = np.max(diferencias)
    
    return {
        'd_calculado': d_stat,
        'd_critico': d_critico,
        'p_value': p_value,
        'acepta_uniformidad': acepta_h0,
        'numeros_ordenados': numeros_ord,
        'cdf_empirica': cdf_empirica,
        'diferencias': diferencias
    }

# Ejemplo
numeros = np.random.random(50)
resultado = prueba_kolmogorov_smirnov(numeros)

print(f"D calculado: {resultado['d_calculado']:.4f}")
print(f"D crítico: {resultado['d_critico']:.4f}")
print(f"P-value: {resultado['p_value']:.4f}")
print(f"¿Acepta uniformidad? {'SÍ' if resultado['acepta_uniformidad'] else 'NO'}")

# Visualización
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(resultado['numeros_ordenados'], resultado['cdf_empirica'], 
         'b-', label='CDF Empírica', linewidth=2)
plt.plot([0, 1], [0, 1], 'r--', label='CDF Teórica (Uniforme)', linewidth=2)
plt.xlabel('x')
plt.ylabel('F(x)')
plt.title('Prueba Kolmogorov-Smirnov')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

## Comparación de Pruebas

| Aspecto | Chi-Cuadrada | Kolmogorov-Smirnov |
|---------|--------------|-------------------|
| **Tipo** | Paramétrica | No paramétrica |
| **Datos** | Agrupados en intervalos | Individuales |
| **Potencia** | Buena para n grande | Mejor para n pequeño |
| **Sensibilidad** | Colas de distribución | Toda la distribución |
| **Complejidad** | Simple | Moderada |
| **Uso común** | Muy frecuente | Frecuente |

### Cuándo usar cada una

**Chi-Cuadrada:**
- ✅ Muestras grandes (n > 50)
- ✅ Cuando se quiere ver distribución por intervalos
- ✅ Fácil de explicar a no-estadísticos

**Kolmogorov-Smirnov:**
- ✅ Muestras pequeñas (n < 50)
- ✅ Cuando se quiere máxima potencia
- ✅ No se quiere perder información agrupando

---

## Ejercicios Prácticos

### Ejercicio 1: Chi-Cuadrada Manual

Dados 40 números divididos en 4 intervalos:

| Intervalo | Observada |
|-----------|-----------|
| [0.0, 0.25) | 12 |
| [0.25, 0.50) | 8 |
| [0.50, 0.75) | 11 |
| [0.75, 1.00) | 9 |

¿Son uniformes? (α = 0.05)

**Solución:**

```python
# Datos
observadas = np.array([12, 8, 11, 9])
n = 40
k = 4
esperadas = np.full(k, n/k)  # [10, 10, 10, 10]

# Chi-cuadrada
chi2 = np.sum((observadas - esperadas)**2 / esperadas)
print(f"χ² = {chi2:.2f}")

# Valor crítico (k-1 = 3 grados de libertad, α=0.05)
chi2_critico = 7.815
print(f"χ² crítico = {chi2_critico}")

# Decisión
if chi2 < chi2_critico:
    print("✓ Acepta uniformidad")
else:
    print("✗ Rechaza uniformidad")

# Respuesta: χ² = 1.0 < 7.815 → Acepta
```

### Ejercicio 2: K-S con Python

Genere 30 números con LCG (a=5, c=3, m=16, X₀=7) y pruebe uniformidad.

**Solución:**

```python
class LCG:
    def __init__(self, semilla, a, c, m):
        self.actual = semilla
        self.a, self.c, self.m = a, c, m
    
    def siguiente(self):
        self.actual = (self.a * self.actual + self.c) % self.m
        return self.actual / self.m

# Generar números
gen = LCG(7, 5, 3, 16)
numeros = [gen.siguiente() for _ in range(30)]

# Prueba K-S
d_stat, p_value = stats.kstest(numeros, 'uniform')

print(f"D = {d_stat:.4f}")
print(f"P-value = {p_value:.4f}")

if p_value > 0.05:
    print("✓ Acepta uniformidad")
else:
    print("✗ Rechaza uniformidad")
```

### Ejercicio 3: Comparación de Generadores

Compare uniformidad de:
1. LCG simple
2. Mersenne Twister
3. PCG

Usando ambas pruebas (Chi² y K-S).

**Solución:**

```python
# Generar números
n = 100

# LCG
gen_lcg = LCG(1, 5, 3, 16)
nums_lcg = [gen_lcg.siguiente() for _ in range(n)]

# Mersenne Twister
np.random.seed(42)
nums_mt = np.random.random(n)

# PCG
rng = np.random.default_rng(42)
nums_pcg = rng.random(n)

# Probar cada uno
for nombre, nums in [('LCG', nums_lcg), ('MT', nums_mt), ('PCG', nums_pcg)]:
    print(f"\n{nombre}:")
    
    # Chi-cuadrada
    chi2_res = prueba_chi_cuadrada(nums, k=10)
    print(f"  Chi²: {chi2_res['chi2_calculado']:.2f}, "
          f"p={chi2_res['p_value']:.4f}, "
          f"{'✓' if chi2_res['acepta_uniformidad'] else '✗'}")
    
    # K-S
    ks_res = prueba_kolmogorov_smirnov(nums)
    print(f"  K-S:  D={ks_res['d_calculado']:.4f}, "
          f"p={ks_res['p_value']:.4f}, "
          f"{'✓' if ks_res['acepta_uniformidad'] else '✗'}")
```

---

## Errores Comunes

### Error 1: Muy pocos intervalos

❌ **Incorrecto:** k = 2 intervalos para n = 100
✅ **Correcto:** k = 10 o k = √100 = 10

**Razón:** Pocos intervalos no detectan problemas

### Error 2: Frecuencias esperadas muy pequeñas

❌ **Incorrecto:** E < 5 en algún intervalo
✅ **Correcto:** Asegurar E ≥ 5 en todos

**Solución:** Reducir k o aumentar n

### Error 3: Confundir hipótesis

❌ **Incorrecto:** "Acepto que NO es uniforme"
✅ **Correcto:** "No rechazo que es uniforme" o "Rechazo uniformidad"

### Error 4: Ignorar el p-value

❌ **Incorrecto:** Solo mirar si χ² < crítico
✅ **Correcto:** También reportar p-value

### Error 5: Una sola prueba

❌ **Incorrecto:** Solo hacer Chi-cuadrada
✅ **Correcto:** Hacer múltiples pruebas (Chi², K-S, etc.)

---

## Resumen

**Conceptos clave:**
- Uniformidad es fundamental para validez de simulación
- Chi-cuadrada: prueba más común, agrupa datos
- K-S: más potente, usa datos individuales
- Ambas prueban H₀: "los números son uniformes"

**Recomendaciones:**
- Usar ambas pruebas para mayor confianza
- n ≥ 50 para Chi-cuadrada
- Reportar siempre p-value
- Visualizar resultados

---

*Referencia: Programa SCD-1022 - TecNM*  
*Fuentes: Law & Kelton (1991), Knuth (1997)*


---

<div align="center">

⬅️ [2.2 Pruebas de Validación](2.2.md) &nbsp;&nbsp;|&nbsp;&nbsp; [2.2.2 Aleatoriedad](2.2.2.md) ➡️

</div>
