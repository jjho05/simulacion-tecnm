# 3.4.3 Método de composición

El método de composición se utiliza cuando la distribución objetivo puede expresarse como una **mezcla ponderada** de otras distribuciones más simples. Este método es especialmente útil para modelar heterogeneidad en poblaciones, distribuciones multimodales, y datos empíricos sin distribución teórica clara.

---

## Fundamento Teórico

### Definición de Mezcla de Distribuciones

Si la densidad $f(x)$ puede escribirse como una combinación lineal de densidades:

$$f(x) = \sum_{i=1}^{n} p_i f_i(x)$$

donde:
- $p_i \geq 0$ son las **probabilidades de mezcla** (pesos)
- $\sum_{i=1}^{n} p_i = 1$
- $f_i(x)$ son densidades de probabilidad válidas

Entonces $f(x)$ es una **mezcla** de las distribuciones $f_i(x)$.

### Interpretación Probabilística

Podemos pensar en una mezcla como un proceso de dos pasos:

1. **Seleccionar** una distribución componente $i$ con probabilidad $p_i$
2. **Generar** un valor de esa distribución $f_i(x)$

**Ejemplo conceptual:**

Una tienda tiene dos tipos de clientes:
- 70% son clientes rápidos (tiempo de servicio ~ Exp(λ=5))
- 30% son clientes lentos (tiempo de servicio ~ Exp(λ=0.5))

El tiempo de servicio general es una **mezcla** de dos exponenciales.

---

## Algoritmo General

### Procedimiento Paso a Paso

**Paso 1:** Generar $R_1 \sim U[0,1]$

**Paso 2:** Seleccionar la distribución componente $i$ tal que:
$$\sum_{j=1}^{i-1} p_j < R_1 \leq \sum_{j=1}^{i} p_j$$

**Paso 3:** Generar un valor $X$ de la distribución $f_i(x)$ seleccionada

**Paso 4:** Retornar $X$

### Implementación General

```python
import numpy as np

def generar_mezcla(distribuciones, probabilidades, size=1):
    """
    Genera variables de una mezcla de distribuciones.
    
    Args:
        distribuciones: Lista de funciones generadoras
        probabilidades: Lista de pesos (deben sumar 1)
        size: Número de muestras
    
    Returns:
        Array de valores generados
    """
    resultados = []
    
    # Probabilidades acumuladas
    prob_acum = np.cumsum(probabilidades)
    
    for _ in range(size):
        # Paso 1: Seleccionar componente
        R1 = np.random.random()
        
        # Encontrar índice de la distribución
        for i, p_acum in enumerate(prob_acum):
            if R1 <= p_acum:
                componente = i
                break
        
        # Paso 2: Generar de la distribución seleccionada
        X = distribuciones[componente]()
        resultados.append(X)
    
    return np.array(resultados)

# Ejemplo de uso
def exp_rapida():
    return -np.log(np.random.random()) / 5

def exp_lenta():
    return -np.log(np.random.random()) / 0.5

# Mezcla: 70% rápida, 30% lenta
muestras = generar_mezcla(
    distribuciones=[exp_rapida, exp_lenta],
    probabilidades=[0.7, 0.3],
    size=10000
)

print(f"Media simulada: {np.mean(muestras):.4f}")
print(f"Desv.Est. simulada: {np.std(muestras):.4f}")
```

---

## Aplicaciones Principales

### 1. Distribución Hiperexponencial

**Definición:** Mezcla de dos o más distribuciones exponenciales con diferentes tasas.

**PDF (2 componentes):**
$$f(x) = p \lambda_1 e^{-\lambda_1 x} + (1-p) \lambda_2 e^{-\lambda_2 x}, \quad x \geq 0$$

**Parámetros:**
- $p$: Probabilidad de la primera componente
- $\lambda_1, \lambda_2$: Tasas de las exponenciales

**Media y Varianza:**
$$E[X] = \frac{p}{\lambda_1} + \frac{1-p}{\lambda_2}$$

$$\text{Var}(X) = \frac{p}{\lambda_1^2} + \frac{1-p}{\lambda_2^2} - E[X]^2$$

**Característica clave:** Coeficiente de variación $CV > 1$ (mayor variabilidad que exponencial simple)

**Generación:**

```python
def generar_hiperexponencial(p, lambda1, lambda2, size=1):
    """Genera variables Hiperexponenciales (mezcla de 2 exponenciales)"""
    resultados = []
    
    for _ in range(size):
        R1 = np.random.random()
        R2 = np.random.random()
        
        if R1 <= p:
            # Usar primera exponencial
            X = -np.log(R2) / lambda1
        else:
            # Usar segunda exponencial
            X = -np.log(R2) / lambda2
        
        resultados.append(X)
    
    return np.array(resultados)

# Ejemplo: Tiempos de servicio heterogéneos
p = 0.7
lambda1, lambda2 = 5, 0.5

muestras = generar_hiperexponencial(p, lambda1, lambda2, size=10000)

# Verificar
media_teo = p/lambda1 + (1-p)/lambda2
var_teo = p/lambda1**2 + (1-p)/lambda2**2 - media_teo**2

print(f"Media teórica: {media_teo:.4f}")
print(f"Media simulada: {np.mean(muestras):.4f}")
print(f"Varianza teórica: {var_teo:.4f}")
print(f"Varianza simulada: {np.var(muestras):.4f}")

# Coeficiente de variación
cv = np.sqrt(var_teo) / media_teo
print(f"CV: {cv:.4f} (>1 indica alta variabilidad)")

# Visualizar
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# Histograma
plt.subplot(1, 2, 1)
plt.hist(muestras, bins=50, density=True, alpha=0.7, edgecolor='black', label='Simulado')

# PDF teórica
x = np.linspace(0, 10, 1000)
pdf_teo = p * lambda1 * np.exp(-lambda1 * x) + (1-p) * lambda2 * np.exp(-lambda2 * x)
plt.plot(x, pdf_teo, 'r-', linewidth=2, label='Teórico')

plt.xlabel('x')
plt.ylabel('Densidad')
plt.title('PDF: Hiperexponencial')
plt.legend()
plt.grid(True, alpha=0.3)

# Componentes individuales
plt.subplot(1, 2, 2)
pdf1 = lambda1 * np.exp(-lambda1 * x)
pdf2 = lambda2 * np.exp(-lambda2 * x)

plt.plot(x, pdf1, '--', linewidth=2, label=f'Exp(λ₁={lambda1}), peso={p}')
plt.plot(x, pdf2, '--', linewidth=2, label=f'Exp(λ₂={lambda2}), peso={1-p}')
plt.plot(x, pdf_teo, 'k-', linewidth=2, label='Mezcla')

plt.xlabel('x')
plt.ylabel('Densidad')
plt.title('Componentes de la Mezcla')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

### 2. Distribución Empírica (Datos Históricos)

**Problema:** Tenemos datos históricos sin distribución teórica clara.

**Solución:** Usar la distribución empírica directamente.

**Ejemplo: Tiempos de servicio observados**

Datos: [2, 3, 3, 5, 7, 7, 7, 9] minutos

**Paso 1: Calcular frecuencias**

| Valor | Frecuencia | Probabilidad |
|-------|------------|--------------|
| 2 | 1 | 1/8 = 0.125 |
| 3 | 2 | 2/8 = 0.250 |
| 5 | 1 | 1/8 = 0.125 |
| 7 | 3 | 3/8 = 0.375 |
| 9 | 1 | 1/8 = 0.125 |

**Paso 2: Probabilidades acumuladas**

| Valor | P(X=x) | P(X≤x) |
|-------|--------|--------|
| 2 | 0.125 | 0.125 |
| 3 | 0.250 | 0.375 |
| 5 | 0.125 | 0.500 |
| 7 | 0.375 | 0.875 |
| 9 | 0.125 | 1.000 |

**Generación:**

```python
def generar_empirica(valores, probabilidades, size=1):
    """Genera variables de una distribución empírica"""
    prob_acum = np.cumsum(probabilidades)
    resultados = []
    
    for _ in range(size):
        R = np.random.random()
        
        # Buscar en qué intervalo cae R
        for i, p_acum in enumerate(prob_acum):
            if R <= p_acum:
                resultados.append(valores[i])
                break
    
    return np.array(resultados)

# Datos históricos
valores = [2, 3, 5, 7, 9]
probabilidades = [1/8, 2/8, 1/8, 3/8, 1/8]

# Generar
muestras = generar_empirica(valores, probabilidades, size=10000)

# Verificar
print("Frecuencias simuladas:")
for v in valores:
    freq = np.sum(muestras == v) / 10000
    freq_teo = probabilidades[valores.index(v)]
    print(f"  P(X={v}): Simulado={freq:.4f}, Teórico={freq_teo:.4f}")

# Visualizar
plt.figure(figsize=(10, 6))
plt.hist(muestras, bins=np.arange(1.5, 10.5, 1), density=True, alpha=0.7, edgecolor='black', label='Simulado', align='mid')

# PMF teórica
plt.stem(valores, probabilidades, linefmt='r-', markerfmt='ro', basefmt=' ', label='Teórico')

plt.xlabel('Tiempo de servicio (minutos)')
plt.ylabel('Probabilidad')
plt.title('Distribución Empírica de Tiempos de Servicio')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

### 3. Distribución Normal Mixta (Bimodal)

**Aplicación:** Modelar poblaciones con dos subgrupos distintos.

**Ejemplo:** Alturas de adultos (hombres y mujeres)

```python
def generar_normal_mixta(p, mu1, sigma1, mu2, sigma2, size=1):
    """Genera variables de una mezcla de dos normales"""
    resultados = []
    
    for _ in range(size):
        R1 = np.random.random()
        
        # Box-Muller para generar normal
        R2 = np.random.random()
        R3 = np.random.random()
        Z = np.sqrt(-2*np.log(R2)) * np.cos(2*np.pi*R3)
        
        if R1 <= p:
            # Primera normal
            X = mu1 + sigma1 * Z
        else:
            # Segunda normal
            X = mu2 + sigma2 * Z
        
        resultados.append(X)
    
    return np.array(resultados)

# Ejemplo: Alturas (cm)
# 50% hombres: N(175, 7)
# 50% mujeres: N(162, 6)

muestras = generar_normal_mixta(p=0.5, mu1=175, sigma1=7, mu2=162, sigma2=6, size=10000)

# Visualizar
from scipy.stats import norm

plt.figure(figsize=(10, 6))
plt.hist(muestras, bins=50, density=True, alpha=0.7, edgecolor='black', label='Simulado')

# PDF teórica
x = np.linspace(140, 200, 1000)
pdf1 = norm.pdf(x, 175, 7)
pdf2 = norm.pdf(x, 162, 6)
pdf_mezcla = 0.5 * pdf1 + 0.5 * pdf2

plt.plot(x, pdf1, '--', linewidth=2, alpha=0.5, label='Hombres N(175,7)')
plt.plot(x, pdf2, '--', linewidth=2, alpha=0.5, label='Mujeres N(162,6)')
plt.plot(x, pdf_mezcla, 'r-', linewidth=2, label='Mezcla')

plt.xlabel('Altura (cm)')
plt.ylabel('Densidad')
plt.title('Distribución Bimodal de Alturas')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

## Ventajas y Limitaciones

### Ventajas

1. **Flexibilidad extrema:** Puede modelar distribuciones muy complejas
2. **Multimodalidad:** Ideal para distribuciones con múltiples picos
3. **Heterogeneidad:** Modela poblaciones con subgrupos distintos
4. **Datos empíricos:** Funciona directamente con datos históricos
5. **Interpretabilidad:** Cada componente tiene significado físico

### Limitaciones

1. **Requiere conocer la descomposición:** Necesitas identificar las componentes
2. **Múltiples parámetros:** Más parámetros = más difícil de estimar
3. **Dos números aleatorios:** Necesita $R_1$ (selección) y $R_2$ (generación)
4. **Validación compleja:** Difícil verificar si la mezcla es correcta

---

## Ejercicios Prácticos

### Ejercicio 1: Centro de Atención Médica

Un centro médico tiene tres tipos de pacientes:
- 60% consultas rápidas: Exp(λ=12 pacientes/hora)
- 30% consultas normales: Exp(λ=4 pacientes/hora)
- 10% consultas complejas: Exp(λ=1 paciente/hora)

1. Genere 10,000 tiempos de atención
2. Calcule el tiempo promedio de atención
3. ¿Cuál es la probabilidad de que una consulta tarde más de 30 minutos?

**Solución:**

```python
def generar_tiempos_atencion(size):
    """Genera tiempos de atención (mezcla de 3 exponenciales)"""
    probabilidades = [0.6, 0.3, 0.1]
    lambdas = [12, 4, 1]  # pacientes/hora
    
    resultados = []
    prob_acum = np.cumsum(probabilidades)
    
    for _ in range(size):
        R1 = np.random.random()
        R2 = np.random.random()
        
        # Seleccionar tipo de consulta
        if R1 <= prob_acum[0]:
            lambd = lambdas[0]
        elif R1 <= prob_acum[1]:
            lambd = lambdas[1]
        else:
            lambd = lambdas[2]
        
        # Generar tiempo
        tiempo = -np.log(R2) / lambd
        resultados.append(tiempo)
    
    return np.array(resultados)

# 1. Generar
tiempos = generar_tiempos_atencion(10000)

# 2. Tiempo promedio
tiempo_promedio = np.mean(tiempos)
print(f"Tiempo promedio de atención: {tiempo_promedio*60:.2f} minutos")

# 3. P(X > 0.5 horas = 30 minutos)
prob_mas_30min = np.mean(tiempos > 0.5)
print(f"P(X > 30 min): {prob_mas_30min*100:.2f}%")

# Visualizar
plt.figure(figsize=(10, 6))
plt.hist(tiempos, bins=50, density=True, alpha=0.7, edgecolor='black')
plt.axvline(0.5, color='r', linestyle='--', linewidth=2, label='30 minutos')
plt.xlabel('Tiempo de atención (horas)')
plt.ylabel('Densidad')
plt.title('Distribución de Tiempos de Atención (Mezcla de 3 Exponenciales)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xlim(0, 3)
plt.show()
```

### Ejercicio 2: Análisis de Datos Reales

Dada una muestra de datos reales, crear y validar una distribución empírica.

**Datos:** Tiempos de espera en minutos: [5, 8, 8, 10, 12, 12, 12, 15, 15, 20]

```python
# Datos
datos = [5, 8, 8, 10, 12, 12, 12, 15, 15, 20]

# Calcular frecuencias
from collections import Counter
conteo = Counter(datos)

valores = sorted(conteo.keys())
frecuencias = [conteo[v] for v in valores]
probabilidades = [f/len(datos) for f in frecuencias]

print("Distribución empírica:")
for v, p in zip(valores, probabilidades):
    print(f"  P(X={v}) = {p:.3f}")

# Generar y validar
muestras = generar_empirica(valores, probabilidades, size=10000)

print(f"\nMedia original: {np.mean(datos):.2f}")
print(f"Media simulada: {np.mean(muestras):.2f}")
```

---

## Casos de Estudio

### Caso 1: Modelado de Tráfico de Red

**Problema:** El tráfico de red tiene dos tipos de paquetes:
- 80% paquetes pequeños (tamaño ~ Exp(λ=100 KB))
- 20% paquetes grandes (tamaño ~ Exp(λ=10 KB))

**Pregunta:** ¿Cuál es el tamaño promedio de paquete y la probabilidad de que un paquete sea mayor a 50 KB?

```python
# Parámetros
p_pequeno = 0.8
lambda_pequeno = 100  # KB
lambda_grande = 10    # KB

# Generar tamaños de paquetes
tamanos = generar_hiperexponencial(p_pequeno, lambda_pequeno, lambda_grande, size=100000)

# Estadísticos
tamano_promedio = np.mean(tamanos)
prob_mayor_50 = np.mean(tamanos > 50)

print(f"Tamaño promedio de paquete: {tamano_promedio:.2f} KB")
print(f"P(Tamaño > 50 KB): {prob_mayor_50*100:.2f}%")

# Visualizar
plt.figure(figsize=(10, 6))
plt.hist(tamanos, bins=100, density=True, alpha=0.7, edgecolor='black')
plt.axvline(50, color='r', linestyle='--', linewidth=2, label='50 KB')
plt.xlabel('Tamaño de paquete (KB)')
plt.ylabel('Densidad')
plt.title('Distribución de Tamaños de Paquetes de Red')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xlim(0, 200)
plt.show()
```

---

## Comparación con Otros Métodos

### Tabla Comparativa

| Aspecto | Composición | Transformada Inversa | Convolución |
|---------|-------------|---------------------|-------------|
| **Complejidad** | Media | Simple | Simple |
| **Flexibilidad** | ✅ Muy alta | ⚠️ Limitada | ⚠️ Limitada |
| **Multimodalidad** | ✅ Sí | ❌ No | ❌ No |
| **Números aleatorios** | 2+ por muestra | 1 por muestra | $n$ por muestra |
| **Interpretabilidad** | ✅ Alta | ⚠️ Media | ✅ Alta |
| **Uso típico** | Heterogeneidad | Distribuciones simples | Sumas naturales |

---

## Resumen y Mejores Prácticas

**Conceptos Clave:**
- Composición: Mezcla ponderada de distribuciones
- Hiperexponencial: Mezcla de exponenciales (alta variabilidad)
- Empírica: Usar datos históricos directamente
- Bimodal: Mezcla de normales (dos picos)

**Cuándo Usar:**
- Poblaciones heterogéneas (diferentes tipos de clientes)
- Distribuciones multimodales
- Datos empíricos sin distribución teórica
- Modelar variabilidad extrema (CV > 1)

**Cuándo NO Usar:**
- Distribuciones simples (usar transformada inversa)
- Cuando no se conoce la descomposición
- Si la eficiencia es crítica (requiere 2+ uniformes)

---

*Referencia: Programa SCD-1022 - TecNM*
*Fuentes: Law & Kelton (1991), Ross (2014), Devroye (1986)*


---

<div align="center">

⬅️ [3.4.2 Convolución](3.4.2.md) &nbsp;&nbsp;|&nbsp;&nbsp; [3.5 Procedimientos Especiales](3.5.md) ➡️

</div>
