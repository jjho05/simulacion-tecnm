# 3.6 Pruebas estadísticas para validar generadores de variables aleatorias

Después de generar variables aleatorias, es **crítico** verificar que sigan la distribución deseada. Un generador defectuoso puede invalidar completamente los resultados de una simulación. Esta sección cubre las pruebas estadísticas fundamentales para validar generadores.

---

## Importancia de la Validación

### ¿Por qué validar?

1. **Errores de implementación:** Un error en el código puede producir distribuciones incorrectas
2. **Calidad del RNG base:** Si los números uniformes son defectuosos, las variables generadas también lo serán
3. **Parámetros incorrectos:** Verificar que los parámetros se aplicaron correctamente
4. **Confianza en resultados:** Solo podemos confiar en simulaciones con generadores validados

### Ejemplo de fallo

```python
# Generador INCORRECTO de exponencial
def exponencial_malo(lambd):
    return -np.log(np.random.random()) * lambd  # ERROR: debería ser /lambd

# Este error produciría media = λ² en lugar de 1/λ
```

---

## Prueba de Bondad de Ajuste (Chi-Cuadrada)

### Concepto

Verifica si los datos generados se ajustan a la distribución teórica dividiendo el rango en intervalos y comparando frecuencias observadas vs esperadas.

### Procedimiento Paso a Paso

**Paso 1:** Dividir el rango en $k$ intervalos (típicamente $k \approx \sqrt{n}$)

**Paso 2:** Contar frecuencias observadas $O_i$ en cada intervalo

**Paso 3:** Calcular frecuencias esperadas:
$$E_i = n \cdot P(\text{intervalo } i)$$

**Paso 4:** Calcular estadístico Chi-cuadrada:
$$\chi^2_0 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i}$$

**Paso 5:** Comparar con valor crítico $\chi^2_{\alpha, k-p-1}$ donde $p$ es el número de parámetros estimados

**Decisión:** Si $\chi^2_0 < \chi^2_{\alpha, k-p-1}$, aceptar que los datos siguen la distribución

### Implementación Completa

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

def prueba_chi_cuadrada_continua(muestras, distribucion_teorica, k=10, alpha=0.05):
    """
    Prueba Chi-cuadrada para distribuciones continuas.
    
    Args:
        muestras: Array de valores generados
        distribucion_teorica: Objeto de scipy.stats
        k: Número de intervalos
        alpha: Nivel de significancia
    """
    n = len(muestras)
    
    # Crear intervalos usando percentiles
    percentiles = np.linspace(0, 100, k+1)
    limites = np.percentile(muestras, percentiles)
    
    # Contar frecuencias observadas
    obs, _ = np.histogram(muestras, bins=limites)
    
    # Frecuencias esperadas (uniformes por construcción de percentiles)
    esp = np.full(k, n/k)
    
    # Chi-cuadrada
    chi2_stat = np.sum((obs - esp)**2 / esp)
    
    # Grados de libertad
    df = k - 1
    
    # Valor crítico
    chi2_crit = stats.chi2.ppf(1 - alpha, df)
    
    # P-value
    p_value = 1 - stats.chi2.cdf(chi2_stat, df)
    
    # Resultados
    print("=== PRUEBA CHI-CUADRADA ===")
    print(f"Estadístico χ²: {chi2_stat:.4f}")
    print(f"Valor crítico: {chi2_crit:.4f}")
    print(f"P-value: {p_value:.4f}")
    print(f"Resultado: {'✓ PASA' if chi2_stat < chi2_crit else '✗ FALLA'}")
    
    return {
        'chi2_stat': chi2_stat,
        'chi2_crit': chi2_crit,
        'p_value': p_value,
        'acepta': chi2_stat < chi2_crit
    }

# Ejemplo: Validar generador exponencial
from scipy.stats import expon

lambd = 2
muestras_exp = -np.log(np.random.random(1000)) / lambd

dist_teo = expon(scale=1/lambd)
resultado = prueba_chi_cuadrada_continua(muestras_exp, dist_teo, k=10)
```

---

## Prueba de Kolmogorov-Smirnov

### Concepto

Compara la función de distribución acumulada empírica $F_n(x)$ con la teórica $F(x)$.

**Estadístico:**
$$D_n = \max_x |F_n(x) - F(x)|$$

donde:
- $F_n(x) = \frac{1}{n}\sum_{i=1}^{n} I(X_i \leq x)$ (proporción de valores $\leq x$)
- $F(x)$ = CDF teórica

### Ventajas sobre Chi-cuadrada

1. **No requiere agrupar datos** en intervalos
2. **Más potente** para detectar diferencias en la forma de la distribución
3. **Funciona mejor con muestras pequeñas**

### Implementación

```python
def prueba_kolmogorov_smirnov(muestras, distribucion_teorica, alpha=0.05):
    """
    Prueba de Kolmogorov-Smirnov.
    
    Args:
        muestras: Array de valores generados
        distribucion_teorica: Objeto de scipy.stats
        alpha: Nivel de significancia
    """
    # Calcular estadístico D
    d_stat, p_value = stats.kstest(muestras, distribucion_teorica.cdf)
    
    # Valor crítico (aproximación)
    n = len(muestras)
    d_crit = 1.36 / np.sqrt(n)  # Para α=0.05
    
    print("=== PRUEBA KOLMOGOROV-SMIRNOV ===")
    print(f"Estadístico D: {d_stat:.4f}")
    print(f"Valor crítico: {d_crit:.4f}")
    print(f"P-value: {p_value:.4f}")
    print(f"Resultado: {'✓ PASA' if d_stat < d_crit else '✗ FALLA'}")
    
    # Visualizar
    plt.figure(figsize=(10, 6))
    
    # CDF empírica
    x_sorted = np.sort(muestras)
    y_empirica = np.arange(1, len(x_sorted)+1) / len(x_sorted)
    
    plt.step(x_sorted, y_empirica, where='post', label='CDF Empírica', linewidth=2)
    
    # CDF teórica
    x_teo = np.linspace(muestras.min(), muestras.max(), 1000)
    y_teorica = distribucion_teorica.cdf(x_teo)
    plt.plot(x_teo, y_teorica, 'r-', label='CDF Teórica', linewidth=2)
    
    plt.xlabel('x')
    plt.ylabel('F(x)')
    plt.title('Prueba Kolmogorov-Smirnov')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
    
    return {
        'd_stat': d_stat,
        'd_crit': d_crit,
        'p_value': p_value,
        'acepta': d_stat < d_crit
    }

# Ejemplo
resultado_ks = prueba_kolmogorov_smirnov(muestras_exp, dist_teo)
```

---

## Gráficos Q-Q (Quantile-Quantile)

### Concepto

Método **visual** para comparar cuantiles teóricos vs empíricos.

**Interpretación:**
- Si los puntos se alinean en una recta diagonal → Distribución correcta
- Desviaciones sistemáticas → Distribución incorrecta

### Implementación

```python
def grafico_qq(muestras, distribucion_teorica):
    """Crea gráfico Q-Q para validación visual"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # Q-Q Plot
    stats.probplot(muestras, dist=distribucion_teorica, plot=ax1)
    ax1.set_title('Q-Q Plot')
    ax1.grid(True, alpha=0.3)
    
    # Histograma con PDF
    ax2.hist(muestras, bins=30, density=True, alpha=0.7, edgecolor='black', label='Datos')
    
    x = np.linspace(muestras.min(), muestras.max(), 1000)
    pdf_teo = distribucion_teorica.pdf(x)
    ax2.plot(x, pdf_teo, 'r-', linewidth=2, label='PDF Teórica')
    
    ax2.set_xlabel('x')
    ax2.set_ylabel('Densidad')
    ax2.set_title('Histograma vs PDF Teórica')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# Ejemplo
grafico_qq(muestras_exp, dist_teo)
```

---

## Prueba de Momentos

### Concepto

Comparar estadísticos muestrales (media, varianza) con los teóricos.

### Prueba t para la Media

**Hipótesis:**
- $H_0: \mu = \mu_0$ (media teórica)
- $H_1: \mu \neq \mu_0$

**Estadístico:**
$$t_0 = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}$$

```python
def prueba_t_media(muestras, media_teorica, alpha=0.05):
    """Prueba t para la media"""
    n = len(muestras)
    media_muestra = np.mean(muestras)
    s = np.std(muestras, ddof=1)
    
    # Estadístico t
    t_stat = (media_muestra - media_teorica) / (s / np.sqrt(n))
    
    # Valor crítico (dos colas)
    t_crit = stats.t.ppf(1 - alpha/2, n-1)
    
    # P-value
    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n-1))
    
    print("=== PRUEBA t PARA LA MEDIA ===")
    print(f"Media teórica: {media_teorica:.4f}")
    print(f"Media muestral: {media_muestra:.4f}")
    print(f"Estadístico t: {t_stat:.4f}")
    print(f"Valor crítico: ±{t_crit:.4f}")
    print(f"P-value: {p_value:.4f}")
    print(f"Resultado: {'✓ PASA' if abs(t_stat) < t_crit else '✗ FALLA'}")
    
    return {
        't_stat': t_stat,
        't_crit': t_crit,
        'p_value': p_value,
        'acepta': abs(t_stat) < t_crit
    }

# Ejemplo
media_teo = 1/lambd
prueba_t_media(muestras_exp, media_teo)
```

---

## Batería Completa de Validación

### Función Integrada

```python
def validar_generador_completo(muestras, distribucion_teorica, nombre=''):
    """
    Batería completa de pruebas de validación.
    
    Args:
        muestras: Array de valores generados
        distribucion_teorica: Objeto de scipy.stats
        nombre: Nombre de la distribución
    """
    print(f"{'='*60}")
    print(f"VALIDACIÓN COMPLETA: {nombre}")
    print(f"{'='*60}\n")
    
    # 1. Estadísticos básicos
    media_sim = np.mean(muestras)
    var_sim = np.var(muestras, ddof=1)
    media_teo = distribucion_teorica.mean()
    var_teo = distribucion_teorica.var()
    
    print(f"1. ESTADÍSTICOS BÁSICOS:")
    print(f"   Media:    Teórica={media_teo:.4f}, Simulada={media_sim:.4f}, Error={abs(media_sim-media_teo):.4f}")
    print(f"   Varianza: Teórica={var_teo:.4f}, Simulada={var_sim:.4f}, Error={abs(var_sim-var_teo):.4f}\n")
    
    # 2. Kolmogorov-Smirnov
    d_stat, p_ks = stats.kstest(muestras, distribucion_teorica.cdf)
    print(f"2. KOLMOGOROV-SMIRNOV:")
    print(f"   D = {d_stat:.4f}, p-value = {p_ks:.4f}")
    print(f"   Resultado: {'✓ PASA' if p_ks > 0.05 else '✗ FALLA'}\n")
    
    # 3. Chi-cuadrada
    resultado_chi2 = prueba_chi_cuadrada_continua(muestras, distribucion_teorica, k=10, alpha=0.05)
    print()
    
    # 4. Prueba t para media
    resultado_t = prueba_t_media(muestras, media_teo, alpha=0.05)
    print()
    
    # 5. Visualización
    grafico_qq(muestras, distribucion_teorica)
    
    # 6. Veredicto final
    print(f"{'='*60}")
    print(f"VEREDICTO FINAL:")
    
    pruebas_pasadas = sum([
        p_ks > 0.05,
        resultado_chi2['acepta'],
        resultado_t['acepta'],
        abs(media_sim - media_teo) / media_teo < 0.05,
        abs(var_sim - var_teo) / var_teo < 0.10
    ])
    
    if pruebas_pasadas >= 4:
        print(f"   ✓ GENERADOR VÁLIDO ({pruebas_pasadas}/5 pruebas pasadas)")
    else:
        print(f"   ✗ GENERADOR SOSPECHOSO ({pruebas_pasadas}/5 pruebas pasadas)")
    
    print(f"{'='*60}\n")

# Ejemplo de uso completo
validar_generador_completo(muestras_exp, dist_teo, nombre='Exponencial(λ=2)')
```

---

## Ejercicios Prácticos

### Ejercicio 1: Detectar Generador Defectuoso

Genere 1000 variables usando un generador INCORRECTO y use las pruebas para detectar el error.

```python
# Generador incorrecto (media incorrecta)
muestras_malas = -np.log(np.random.random(1000)) * 2  # Debería ser /2

# Validar
validar_generador_completo(muestras_malas, expon(scale=1/2), nombre='Exponencial INCORRECTA')
```

### Ejercicio 2: Comparar Distribuciones

Genere 10,000 variables de Normal(0,1) y valide usando todas las pruebas.

---

## Resumen y Mejores Prácticas

**Pruebas Fundamentales:**
- Chi-cuadrada: Bondad de ajuste por intervalos
- Kolmogorov-Smirnov: Compara CDFs
- Q-Q Plot: Validación visual
- Prueba t: Verifica media
- Prueba F: Verifica varianza

**Recomendaciones:**
1. Usar múltiples pruebas (no solo una)
2. Validar con muestras grandes (n ≥ 1000)
3. Reportar p-values, no solo decisiones binarias
4. Visualizar siempre (Q-Q plots, histogramas)
5. Comparar estadísticos básicos primero

**Criterio de Aceptación:**
Un generador es válido si pasa al menos 4 de 5 pruebas:
- K-S (p > 0.05)
- Chi-cuadrada (p > 0.05)
- Prueba t para media (p > 0.05)
- Error relativo en media < 5%
- Error relativo en varianza < 10%

---

*Referencia: Programa SCD-1022 - TecNM*
*Fuentes: Law & Kelton (1991), D'Agostino & Stephens (1986)*


---

<div align="center">

⬅️ [3.5 Procedimientos Especiales](3.5.md) &nbsp;&nbsp;|&nbsp;&nbsp; [Inicio Unidad 4](../unidad4/README.md) ➡️

</div>
