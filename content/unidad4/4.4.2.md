# 4.4.2 Pruebas no paramétricas

Las pruebas no paramétricas no asumen una distribución específica de los datos, lo que las hace más robustas pero generalmente menos potentes que las pruebas paramétricas.

## Características de las Pruebas No Paramétricas

### Ventajas:
- No requieren supuestos sobre la distribución de los datos
- Robustas ante valores atípicos
- Aplicables a datos ordinales
- Útiles con muestras pequeñas

### Desventajas:
- Menor potencia estadística cuando los datos son normales
- Menos eficientes con muestras grandes
- Interpretación menos intuitiva

## Prueba de Kolmogorov-Smirnov (K-S)

Compara las distribuciones completas de dos muestras.

### Hipótesis:
- $H_0$: $F_{modelo}(x) = F_{real}(x)$ (las distribuciones son iguales)
- $H_1$: $F_{modelo}(x) \neq F_{real}(x)$ (las distribuciones son diferentes)

### Estadístico de Prueba:
$$D = \max_x |F_{modelo}(x) - F_{real}(x)|$$

donde $F(x)$ es la función de distribución acumulada empírica.

### Decisión:
Si $D < D_{\alpha,n}$, se acepta $H_0$ (las distribuciones son similares).

### Ejemplo:
**Sistema:** Tiempos de llegada de clientes

**Datos reales:** [2.1, 3.5, 1.8, 4.2, 2.9, 3.1, 2.5, 3.8]
**Datos simulados:** [2.3, 3.2, 2.0, 4.0, 3.0, 3.3, 2.7, 3.5]

**Procedimiento:**
1. Ordenar ambas muestras
2. Calcular $F_{real}(x)$ y $F_{sim}(x)$ para cada valor
3. Encontrar la máxima diferencia absoluta
4. Comparar con valor crítico

## Prueba de Mann-Whitney (Wilcoxon de Suma de Rangos)

Compara las medianas de dos muestras independientes.

### Hipótesis:
- $H_0$: Las dos poblaciones tienen la misma mediana
- $H_1$: Las medianas son diferentes

### Procedimiento:
1. Combinar todas las observaciones de ambas muestras
2. Ordenar de menor a mayor
3. Asignar rangos (1, 2, 3, ...)
4. Sumar los rangos de cada grupo
5. Calcular estadístico U

### Estadístico U:
$$U_1 = n_1 n_2 + \frac{n_1(n_1+1)}{2} - R_1$$
$$U_2 = n_1 n_2 + \frac{n_2(n_2+1)}{2} - R_2$$

donde $R_1$ y $R_2$ son las sumas de rangos de cada grupo.

Se usa $U = \min(U_1, U_2)$

### Ejemplo:
**Datos reales:** [5, 7, 6, 8, 9]
**Datos simulados:** [6, 8, 7, 9, 10]

**Paso 1:** Combinar y ordenar
| Valor | 5 | 6 | 6 | 7 | 7 | 8 | 8 | 9 | 9 | 10 |
|-------|---|---|---|---|---|---|---|---|---|----|
| Grupo | R | R | S | R | S | R | S | R | S | S  |
| Rango | 1 | 2.5 | 2.5 | 4.5 | 4.5 | 6.5 | 6.5 | 8.5 | 8.5 | 10 |

**Paso 2:** Sumar rangos
- $R_1 = 1 + 2.5 + 4.5 + 6.5 + 8.5 = 23$
- $R_2 = 2.5 + 4.5 + 6.5 + 8.5 + 10 = 32$

**Paso 3:** Calcular U
- $U_1 = 5 \times 5 + \frac{5 \times 6}{2} - 23 = 17$
- $U_2 = 5 \times 5 + \frac{5 \times 6}{2} - 32 = 8$
- $U = \min(17, 8) = 8$

## Prueba de los Signos

Compara pares de observaciones (modelo vs. real en los mismos escenarios).

### Hipótesis:
- $H_0$: La mediana de las diferencias es cero
- $H_1$: La mediana de las diferencias no es cero

### Procedimiento:
1. Para cada par $(x_i, y_i)$, calcular $d_i = x_i - y_i$
2. Determinar el signo de cada diferencia (+ o -)
3. Ignorar diferencias de cero
4. Contar signos positivos y negativos
5. Usar distribución binomial con $p = 0.5$

### Ejemplo:
| Escenario | Real | Simulado | Diferencia | Signo |
|-----------|------|----------|------------|-------|
| 1         | 5.2  | 5.5      | -0.3       | -     |
| 2         | 4.8  | 4.9      | -0.1       | -     |
| 3         | 5.1  | 5.0      | +0.1       | +     |
| 4         | 5.3  | 5.4      | -0.1       | -     |
| 5         | 4.9  | 5.1      | -0.2       | -     |

Signos negativos: 4, Signos positivos: 1

Si hay diferencia sistemática, uno de los signos predominará significativamente.

## Prueba de Rachas (Runs Test)

Verifica si las diferencias entre modelo y realidad son aleatorias.

### Procedimiento:
1. Calcular diferencias $d_i = x_i - y_i$
2. Clasificar como + o - según la mediana
3. Contar el número de rachas (secuencias consecutivas del mismo signo)
4. Comparar con valores esperados

## Código de Ejemplo en Python

```python
import numpy as np
from scipy import stats

def prueba_kolmogorov_smirnov(datos_reales, datos_simulados, alpha=0.05):
    """
    Realiza prueba K-S para validar modelo de simulación
    """
    # Calcular estadístico K-S
    D_stat, p_value = stats.ks_2samp(datos_reales, datos_simulados)
    
    # Decisión
    if p_value > alpha:
        resultado = "VÁLIDO"
        mensaje = f"No se rechaza H0 (p={p_value:.4f})"
    else:
        resultado = "NO VÁLIDO"
        mensaje = f"Se rechaza H0 (p={p_value:.4f})"
    
    return {
        'estadistico_D': D_stat,
        'p_value': p_value,
        'resultado': resultado,
        'mensaje': mensaje
    }

def prueba_mann_whitney(datos_reales, datos_simulados, alpha=0.05):
    """
    Realiza prueba de Mann-Whitney
    """
    U_stat, p_value = stats.mannwhitneyu(datos_reales, datos_simulados, 
                                          alternative='two-sided')
    
    if p_value > alpha:
        resultado = "VÁLIDO"
        mensaje = f"No se rechaza H0 (p={p_value:.4f})"
    else:
        resultado = "NO VÁLIDO"
        mensaje = f"Se rechaza H0 (p={p_value:.4f})"
    
    return {
        'estadistico_U': U_stat,
        'p_value': p_value,
        'resultado': resultado,
        'mensaje': mensaje
    }

def prueba_signos(datos_reales, datos_simulados, alpha=0.05):
    """
    Realiza prueba de los signos
    """
    diferencias = np.array(datos_reales) - np.array(datos_simulados)
    # Eliminar ceros
    diferencias = diferencias[diferencias != 0]
    
    # Contar signos
    n_positivos = np.sum(diferencias > 0)
    n_negativos = np.sum(diferencias < 0)
    n_total = len(diferencias)
    
    # Usar distribución binomial
    # Bajo H0, esperamos 50% de cada signo
    p_value = 2 * min(
        stats.binom.cdf(n_positivos, n_total, 0.5),
        stats.binom.cdf(n_negativos, n_total, 0.5)
    )
    
    return {
        'n_positivos': n_positivos,
        'n_negativos': n_negativos,
        'p_value': p_value,
        'resultado': 'VÁLIDO' if p_value > alpha else 'NO VÁLIDO'
    }

# Ejemplo de uso
datos_reales = np.array([5.1, 4.9, 5.3, 5.0, 5.2, 4.8, 5.4, 5.1])
datos_simulados = np.array([5.3, 5.0, 5.5, 5.2, 5.1, 5.4, 5.0, 5.3])

print("=== PRUEBAS NO PARAMÉTRICAS ===\n")

resultado_ks = prueba_kolmogorov_smirnov(datos_reales, datos_simulados)
print(f"Prueba K-S: {resultado_ks['resultado']}")
print(f"  {resultado_ks['mensaje']}")
print(f"  D = {resultado_ks['estadistico_D']:.4f}\n")

resultado_mw = prueba_mann_whitney(datos_reales, datos_simulados)
print(f"Prueba Mann-Whitney: {resultado_mw['resultado']}")
print(f"  {resultado_mw['mensaje']}")
print(f"  U = {resultado_mw['estadistico_U']:.4f}\n")

resultado_signos = prueba_signos(datos_reales, datos_simulados)
print(f"Prueba de Signos: {resultado_signos['resultado']}")
print(f"  Positivos: {resultado_signos['n_positivos']}")
print(f"  Negativos: {resultado_signos['n_negativos']}")
print(f"  p-value: {resultado_signos['p_value']:.4f}")
```

## Comparación: Paramétricas vs No Paramétricas

| Aspecto | Paramétricas | No Paramétricas |
|---------|--------------|-----------------|
| Supuestos | Requieren normalidad | Sin supuestos de distribución |
| Potencia | Mayor (si se cumplen supuestos) | Menor |
| Robustez | Sensibles a valores atípicos | Robustas |
| Tamaño de muestra | Más eficientes con n grande | Útiles con n pequeño |
| Interpretación | Directa (parámetros) | Basada en rangos |

## Recomendaciones de Uso

1. **Usar pruebas paramétricas cuando:**
   - Los datos son aproximadamente normales
   - Las muestras son grandes (n > 30)
   - Se requiere máxima potencia estadística

2. **Usar pruebas no paramétricas cuando:**
   - Los datos no son normales
   - Hay valores atípicos
   - Las muestras son pequeñas
   - Los datos son ordinales

3. **Mejor práctica:**
   - Aplicar ambos tipos de pruebas
   - Si ambas coinciden, mayor confianza en el resultado
   - Si difieren, investigar la causa

---
*Referencia: Programa SCD-1022 - TecNM*


---

<div align="center">

⬅️ [4.4.1 Paramétricas](4.4.1.md) &nbsp;&nbsp;|&nbsp;&nbsp; [Inicio Unidad 5](../unidad5/README.md) ➡️

</div>
