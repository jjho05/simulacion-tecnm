# 4.4 Análisis de resultados de la simulación

El análisis de resultados es la fase final y crítica de un proyecto de simulación. No basta con ejecutar el modelo; es esencial validar que los resultados sean correctos, interpretarlos adecuadamente y comunicarlos efectivamente. Esta sección cubre las pruebas estadísticas para validación y el análisis de salidas.

---

## Importancia del Análisis de Resultados

### ¿Por qué es crítico?

**1. Validación del modelo:**
- Un modelo no validado es inútil (o peor, peligroso)
- Decisiones basadas en modelos incorrectos pueden costar millones

**2. Confianza en las conclusiones:**
- Los stakeholders necesitan evidencia estadística
- Resultados sin validación no son creíbles

**3. Detección de errores:**
- Errores de programación
- Supuestos incorrectos
- Datos de entrada erróneos

### Ejemplo de fallo

**Caso real:** Una empresa manufacturera implementó cambios basados en una simulación sin validar. El modelo tenía un error en la lógica de prioridades que no fue detectado. Resultado: **$2M en pérdidas** antes de descubrir el error.

---

## Tipos de Validación

### 1. Validación Conceptual

**Pregunta:** ¿El modelo representa correctamente el sistema real?

**Métodos:**
- Revisión con expertos del dominio
- Comparación de lógica con documentación
- Walkthrough del código

**Ejemplo:**
```python
# ¿Esta lógica es correcta?
if inventario < punto_reorden:
    ordenar(cantidad_pedido)

# Verificar con experto:
# - ¿Es correcto usar < en lugar de <=?
# - ¿Se debe verificar si ya hay un pedido pendiente?
```

### 2. Validación de Datos

**Pregunta:** ¿Los datos de entrada son correctos y representativos?

**Métodos:**
- Análisis de distribuciones
- Pruebas de bondad de ajuste
- Verificación de rangos

**Ejemplo:**
```python
# Verificar que los tiempos de servicio son razonables
assert all(t > 0 for t in tiempos_servicio), "Tiempos negativos!"
assert all(t < 60 for t in tiempos_servicio), "Tiempos > 1 hora sospechosos"
```

### 3. Validación de Resultados (Foco de esta sección)

**Pregunta:** ¿Los resultados del modelo coinciden con el sistema real?

**Métodos:**
- **Pruebas paramétricas** (4.4.1): t-test, F-test, ANOVA
- **Pruebas no paramétricas** (4.4.2): Kolmogorov-Smirnov, Mann-Whitney

---

## Metodología de Validación

### Paso 1: Recolectar Datos Reales

**Fuentes:**
- Observación directa
- Registros históricos
- Sistemas de información (ERP, MES)
- Sensores y IoT

**Cantidad necesaria:**
- Mínimo 30 observaciones por métrica
- Idealmente 100+ para pruebas robustas

**Ejemplo:**
```python
# Recolectar tiempos de espera reales
datos_reales = {
    'fecha': ['2024-01-15', '2024-01-16', ...],
    'tiempo_espera': [12.3, 15.1, 10.8, ...],  # minutos
    'hora_dia': ['09:00', '10:30', ...]
}

df_real = pd.DataFrame(datos_reales)
print(f"Observaciones recolectadas: {len(df_real)}")
print(f"Tiempo promedio: {df_real['tiempo_espera'].mean():.2f} min")
```

### Paso 2: Ejecutar Simulación

**Configuración:**
- Usar los mismos parámetros que el sistema real
- Mismo horizonte de tiempo
- Múltiples réplicas (típicamente 30-100)

**Ejemplo:**
```python
# Ejecutar 50 réplicas
resultados_sim = []

for replica in range(50):
    sistema = SistemaSimulacion(semilla=replica)
    stats = sistema.ejecutar(tiempo=480)  # 8 horas
    resultados_sim.append(stats['tiempo_espera_promedio'])

print(f"Réplicas ejecutadas: {len(resultados_sim)}")
print(f"Tiempo promedio simulado: {np.mean(resultados_sim):.2f} min")
```

### Paso 3: Aplicar Pruebas Estadísticas

**Decisión: ¿Paramétrica o No Paramétrica?**

```python
# Verificar normalidad
from scipy import stats

# Prueba de Shapiro-Wilk
stat_real, p_real = stats.shapiro(datos_reales)
stat_sim, p_sim = stats.shapiro(resultados_sim)

print(f"Normalidad datos reales: p={p_real:.4f}")
print(f"Normalidad datos simulados: p={p_sim:.4f}")

if p_real > 0.05 and p_sim > 0.05:
    print("→ Usar pruebas PARAMÉTRICAS (t-test, F-test)")
else:
    print("→ Usar pruebas NO PARAMÉTRICAS (K-S, Mann-Whitney)")
```

**Aplicar pruebas:**

```python
# Prueba paramétrica (t-test)
t_stat, p_value_t = stats.ttest_ind(datos_reales, resultados_sim)

# Prueba no paramétrica (K-S)
ks_stat, p_value_ks = stats.ks_2samp(datos_reales, resultados_sim)

print(f"\nPrueba t: p-value = {p_value_t:.4f}")
print(f"Prueba K-S: p-value = {p_value_ks:.4f}")

alpha = 0.05
if p_value_t > alpha and p_value_ks > alpha:
    print("✓ MODELO VÁLIDO (ambas pruebas)")
elif p_value_t > alpha or p_value_ks > alpha:
    print("⚠ REVISAR (solo una prueba pasa)")
else:
    print("✗ MODELO NO VÁLIDO (ambas pruebas fallan)")
```

### Paso 4: Interpretar Resultados

**Criterios de decisión:**

| p-value | Interpretación | Acción |
|---------|----------------|--------|
| p > 0.10 | Evidencia fuerte de validez | Aceptar modelo |
| 0.05 < p ≤ 0.10 | Evidencia moderada | Revisar supuestos |
| 0.01 < p ≤ 0.05 | Evidencia débil | Investigar diferencias |
| p ≤ 0.01 | Modelo probablemente inválido | Revisar modelo |

**Análisis visual:**

```python
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Histogramas
ax = axes[0]
ax.hist(datos_reales, bins=20, alpha=0.5, label='Real', edgecolor='black')
ax.hist(resultados_sim, bins=20, alpha=0.5, label='Simulado', edgecolor='black')
ax.set_xlabel('Tiempo de Espera (min)')
ax.set_ylabel('Frecuencia')
ax.set_title('Comparación de Distribuciones')
ax.legend()
ax.grid(True, alpha=0.3)

# Q-Q plot
ax = axes[1]
stats.probplot(datos_reales, dist="norm", plot=ax)
ax.set_title('Q-Q Plot (Datos Reales)')
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### Paso 5: Documentar Validación

**Reporte de validación debe incluir:**

1. **Datos utilizados:**
   - Fuente, cantidad, periodo
   
2. **Pruebas aplicadas:**
   - Tipo de prueba, nivel de significancia
   
3. **Resultados:**
   - Estadísticos, p-values, gráficos
   
4. **Conclusión:**
   - ¿El modelo es válido?
   - Limitaciones conocidas

**Template:**

```markdown
# Reporte de Validación - Sistema de Colas

## Datos
- **Fuente:** Observación directa, 15-30 Enero 2024
- **Métrica:** Tiempo de espera en cola
- **Observaciones reales:** 120
- **Réplicas simuladas:** 50

## Pruebas Estadísticas

### Prueba t (Comparación de medias)
- H0: μ_real = μ_sim
- Estadístico t: 1.23
- p-value: 0.22
- **Conclusión:** No se rechaza H0 (α=0.05)

### Prueba K-S (Comparación de distribuciones)
- H0: F_real = F_sim
- Estadístico D: 0.08
- p-value: 0.45
- **Conclusión:** No se rechaza H0 (α=0.05)

## Conclusión General
✓ **MODELO VÁLIDO**
- Ambas pruebas indican que no hay diferencia significativa
- Error relativo en media: 3.2% (aceptable)
```

---

## Análisis de Sensibilidad

### ¿Qué es?

Evaluar cómo cambian los resultados cuando varían los parámetros de entrada.

### ¿Por qué es importante?

- Identificar parámetros críticos
- Entender robustez del modelo
- Guiar recolección de datos

### Metodología

**1. Seleccionar parámetros a variar:**
- Tasa de llegadas (λ)
- Tasa de servicio (μ)
- Número de servidores (c)

**2. Definir rangos:**
- Típicamente ±20% del valor base

**3. Ejecutar experimentos:**

```python
# Análisis de sensibilidad para λ
lambda_base = 10
resultados_sensibilidad = []

for factor in [0.8, 0.9, 1.0, 1.1, 1.2]:
    lambda_test = lambda_base * factor
    
    # Ejecutar múltiples réplicas
    tiempos_espera = []
    for rep in range(30):
        sistema = SistemaMM1(lambda_test, mu=12, tiempo_sim=1000, semilla=rep)
        stats = sistema.ejecutar()
        tiempos_espera.append(stats['Wq_sim'])
    
    resultados_sensibilidad.append({
        'lambda': lambda_test,
        'factor': factor,
        'Wq_promedio': np.mean(tiempos_espera),
        'Wq_std': np.std(tiempos_espera)
    })

df_sens = pd.DataFrame(resultados_sensibilidad)
print(df_sens)
```

**4. Visualizar:**

```python
plt.figure(figsize=(10, 6))
plt.errorbar(df_sens['lambda'], df_sens['Wq_promedio'], 
             yerr=df_sens['Wq_std'], marker='o', capsize=5)
plt.xlabel('Tasa de Llegadas (λ)')
plt.ylabel('Tiempo de Espera Promedio (Wq)')
plt.title('Análisis de Sensibilidad')
plt.grid(True, alpha=0.3)
plt.show()
```

**5. Interpretar:**

- **Alta sensibilidad:** Pequeños cambios → grandes efectos
  - Requiere datos muy precisos
  - Parámetro crítico para el sistema
  
- **Baja sensibilidad:** Grandes cambios → pequeños efectos
  - Menos crítico
  - Estimaciones aproximadas son suficientes

---

## Estructura de esta Sección

### 4.4.1 Pruebas Paramétricas

Cubre:
- Prueba t (comparación de medias)
- Prueba F (comparación de varianzas)
- ANOVA (múltiples configuraciones)
- Implementación en Python

**Cuándo usar:**
- Datos aproximadamente normales
- Muestras grandes (n > 30)
- Máxima potencia estadística

### 4.4.2 Pruebas No Paramétricas

Cubre:
- Kolmogorov-Smirnov (comparación de distribuciones)
- Mann-Whitney (comparación de medianas)
- Prueba de signos
- Prueba de rachas

**Cuándo usar:**
- Datos no normales
- Valores atípicos
- Muestras pequeñas
- Datos ordinales

---

## Mejores Prácticas

### 1. Usar Múltiples Pruebas

No confiar en una sola prueba. Aplicar tanto paramétricas como no paramétricas.

```python
def validacion_completa(datos_reales, datos_sim, alpha=0.05):
    """Batería completa de pruebas de validación"""
    
    resultados = {}
    
    # Pruebas paramétricas
    t_stat, p_t = stats.ttest_ind(datos_reales, datos_sim)
    resultados['t_test'] = {'estadistico': t_stat, 'p_value': p_t}
    
    f_stat = np.var(datos_reales, ddof=1) / np.var(datos_sim, ddof=1)
    p_f = 1 - stats.f.cdf(f_stat, len(datos_reales)-1, len(datos_sim)-1)
    resultados['f_test'] = {'estadistico': f_stat, 'p_value': p_f}
    
    # Pruebas no paramétricas
    ks_stat, p_ks = stats.ks_2samp(datos_reales, datos_sim)
    resultados['ks_test'] = {'estadistico': ks_stat, 'p_value': p_ks}
    
    mw_stat, p_mw = stats.mannwhitneyu(datos_reales, datos_sim)
    resultados['mw_test'] = {'estadistico': mw_stat, 'p_value': p_mw}
    
    # Resumen
    pruebas_pasadas = sum([
        p_t > alpha,
        p_f > alpha,
        p_ks > alpha,
        p_mw > alpha
    ])
    
    resultados['resumen'] = {
        'pruebas_pasadas': pruebas_pasadas,
        'total_pruebas': 4,
        'porcentaje': pruebas_pasadas / 4 * 100,
        'valido': pruebas_pasadas >= 3  # Al menos 75%
    }
    
    return resultados
```

### 2. Reportar Intervalos de Confianza

No solo promedios, sino también incertidumbre.

```python
# Intervalo de confianza al 95%
media = np.mean(resultados_sim)
std_error = stats.sem(resultados_sim)
ic = stats.t.interval(0.95, len(resultados_sim)-1, media, std_error)

print(f"Media: {media:.2f}")
print(f"IC 95%: [{ic[0]:.2f}, {ic[1]:.2f}]")
```

### 3. Documentar Supuestos

Ser explícito sobre las limitaciones del modelo.

```python
"""
SUPUESTOS DEL MODELO:
1. Llegadas siguen proceso Poisson (verificado con datos)
2. Tiempos de servicio son exponenciales (aproximación razonable)
3. No hay abandonos (tasa real <1%, despreciable)
4. Capacidad infinita (en realidad 100, pero nunca se alcanza)
5. FIFO estricto (en realidad hay prioridades ocasionales)

LIMITACIONES:
- No modela variación por hora del día
- No incluye fallas de equipo
- Asume personal siempre disponible
"""
```

---

## Ejercicios Prácticos

### Ejercicio 1: Validación Completa

Dado:
- Datos reales: [12.3, 15.1, 10.8, 14.2, 11.5, 13.8, 12.9, 14.5]
- Datos simulados: [12.8, 14.9, 11.2, 13.9, 12.1, 14.2, 13.3, 14.1]

a) Aplique prueba t
b) Aplique prueba K-S
c) ¿El modelo es válido?

### Ejercicio 2: Análisis de Sensibilidad

Para un sistema M/M/1 con λ=8, μ=10:

a) Varíe λ de 6 a 10 (incrementos de 0.5)
b) Grafique Wq vs λ
c) ¿Qué tan sensible es el sistema?

---

## Resumen

**Validación es crítica:**
- Modelo sin validar = Modelo inútil
- Usar múltiples pruebas estadísticas
- Documentar supuestos y limitaciones

**Dos enfoques:**
- **Paramétrico** (4.4.1): Mayor potencia si se cumplen supuestos
- **No paramétrico** (4.4.2): Más robusto, menos supuestos

**Análisis de sensibilidad:**
- Identificar parámetros críticos
- Guiar recolección de datos
- Entender robustez

**Próximos pasos:**
- Estudiar 4.4.1 para pruebas paramétricas
- Estudiar 4.4.2 para pruebas no paramétricas
- Practicar con datos reales

---

*Referencia: Programa SCD-1022 - TecNM*
*Las subsecciones 4.4.1 y 4.4.2 desarrollan estos temas en detalle con código completo.*


---

<div align="center">

⬅️ [4.3.2 Inventarios](4.3.2.md) &nbsp;&nbsp;|&nbsp;&nbsp; [4.4.1 Paramétricas](4.4.1.md) ➡️

</div>
